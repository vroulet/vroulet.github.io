---
layout: archive
title: "Teaching"
author_profile: true
redirect_from:
  - /teaching.html
---

{% include base_path %}

## Lecturer  
**Stochastic Modeling of Scientific Data I, II**, *STAT516, Fall 2020, STAT517 Winter 2021.*  
*University of Washington.*  
Stochastic Modeling of Scientific Data I (STAT516): discrete-time Markov chain theory; inference for discrete-time Markov chains; Monte Carlo methods; missing data; hidden Markov models.  
Stochastic Modeling of Scientific Data II (STAT517): Gaussian processes; spatial linear prediction; variograms; Gaussian Markov random fields; Poisson processes; applied stochastic differential equations.    

**Probability I, II**,  *STAT394 Winter 2021, STAT395 Spring 2020, 2021.*  
*University of Washington.*  
Probability I (STAT394): probability definitions and calculus; conditional probability; independence; random variables; expectation and variance; laws of large numbers; normal approximation of the binomial.  
Probability II (STAT395): joint distributions; moment generating function; central limit theorem; conditional distributions.  

**Statistical Learning: Modeling, Prediction, And Computing**,  *STAT538 Winter 2020.*  
*University of Washington. Co-taught with Zaid Harchaoui.*  
Reviews optimization and convex optimization in its relation to statistics. Covers the basics of unconstrained and constrained convex optimization, basics of clustering and classification, entropy, KL divergence and exponential family models, duality, modern learning algorithms like boosting, support vector machines, and variational approximations in inference.

## Teaching Assistant  
**Convex Optimization**,  *2014-2017.*   
*Master Mathematics, Vision, Learning, École Normale Supérieure Paris-Saclay, Paris.*  
Taught by [Alexandre d'Aspremont](https://www.di.ens.fr/~aspremon), see [website](https://www.di.ens.fr/~aspremon/OptConvexeM2.html).  

**Oral Interrogations in Mathematics**,  *2013-2014.*   
*Classes Préparatoires in Mathematics and Physics Lycée Janson de Sailly, Paris.*  

## Tutorials  
**Automatic Differentiation**,  *May 2019, 2020.*  
*Statistical Machine Learning for Data Scientists, University of Washington.*     
Lecture on automatic differentiation with code examples covering: how to compute gradients of
a chain of computations, how to use automatic-differentiation software, how to use automatic-
differentiation beyond gradient computations.  
[slides](/files/auto_diff_tuto.pdf)
[notebook](/files/auto_diff_tuto.ipynb)

**Optimization for deep learning**,  *July 2018.*  
*Summer School on Fundamentals of Data Analysis, University of Wisconsin.*    
Interactive Jupyter Notebook to understand the basics of optimization for
deep learning: automatic-differentiation, convergence guarantees of SGD, illustration of the
batch-normalization effect.   
<!-- [notes](/files/lab1_optimization_notes.pdf)
[notebook](/files/lab1_optimization_deep_learning.ipynb) -->
